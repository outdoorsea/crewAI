#!/usr/bin/env python3
"""
Quick CrewAI Test

A minimal test to verify CrewAI + Ollama is working.
Run this first before the more comprehensive tests.
"""

import sys
from pathlib import Path

# Add the src directory to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def quick_test():
    """Quick test of CrewAI with Ollama."""
    print("âš¡ Quick CrewAI + Ollama Test")
    print("=" * 35)
    
    try:
        # Test imports
        print("ğŸ“¦ Testing imports...")
        from crewai import Agent, Task, Crew
        print("âœ… CrewAI imports successful")
        
        # Test agent creation
        print("ğŸ¤– Creating agent...")
        agent = Agent(
            role="Test Assistant",
            goal="Verify CrewAI + Ollama integration",
            backstory="A simple test agent",
            llm="ollama/llama3.2",
            verbose=False
        )
        print("âœ… Agent created successfully")
        
        # Test task creation
        print("ğŸ“‹ Creating task...")
        task = Task(
            description="Say 'Hello from CrewAI with Ollama!' and nothing else.",
            expected_output="A simple greeting message",
            agent=agent
        )
        print("âœ… Task created successfully")
        
        # Test crew creation
        print("ğŸ‘¥ Creating crew...")
        crew = Crew(
            agents=[agent],
            tasks=[task],
            verbose=False
        )
        print("âœ… Crew created successfully")
        
        # Test execution
        print("ğŸš€ Executing crew...")
        result = crew.kickoff()
        
        print("\n" + "="*35)
        print("ğŸ“ RESULT:")
        print(result)
        print("="*35)
        
        print("\nğŸ‰ Quick test PASSED!")
        print("ğŸ’¡ You can now run the full test suite")
        return True
        
    except ImportError as e:
        print(f"âŒ Import failed: {e}")
        print("ğŸ’¡ Install missing dependencies: pip install crewai")
        return False
    except Exception as e:
        print(f"âŒ Quick test failed: {e}")
        print("ğŸ’¡ Check if Ollama is running: ollama serve")
        print("ğŸ’¡ Check if model is available: ollama pull llama3.2")
        return False

def check_prerequisites():
    """Check if prerequisites are met."""
    print("ğŸ” Checking Prerequisites")
    print("=" * 30)
    
    # Check Ollama
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=3)
        if response.status_code == 200:
            print("âœ… Ollama server is running")
            
            models = response.json().get("models", [])
            model_names = [model.get("name", "") for model in models]
            
            if any("llama3.2" in name for name in model_names):
                print("âœ… llama3.2 model available")
                return True
            else:
                print("âš ï¸  llama3.2 model not found")
                print("ğŸ’¡ Run: ollama pull llama3.2")
                return False
        else:
            print("âŒ Ollama server not responding correctly")
            return False
            
    except Exception as e:
        print("âŒ Cannot connect to Ollama")
        print("ğŸ’¡ Start Ollama: ollama serve")
        return False

if __name__ == "__main__":
    print("âš¡ CrewAI Quick Test")
    print("=" * 25)
    
    if check_prerequisites():
        success = quick_test()
        exit(0 if success else 1)
    else:
        print("\nâŒ Prerequisites not met")
        print("\nğŸ”§ Setup steps:")
        print("1. Install Ollama: brew install ollama")
        print("2. Start Ollama: ollama serve")
        print("3. Pull model: ollama pull llama3.2")
        exit(1)